{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymilvus in ./lib/python3.11/site-packages (2.3.3)\n",
      "Collecting pymilvus\n",
      "  Obtaining dependency information for pymilvus from https://files.pythonhosted.org/packages/5a/c8/fed45f4b9473c07f36647ec83b9e60df241d61c419c34ebc785ee4b57cd7/pymilvus-2.3.5-py3-none-any.whl.metadata\n",
      "  Downloading pymilvus-2.3.5-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: minio in ./lib/python3.11/site-packages (7.1.16)\n",
      "Collecting minio\n",
      "  Obtaining dependency information for minio from https://files.pythonhosted.org/packages/8a/78/4b0fb944cb3f71e6637d8e716593683ea1b41ca5c75ed6a98699d7e31381/minio-7.2.3-py3-none-any.whl.metadata\n",
      "  Using cached minio-7.2.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<=1.58.0,>=1.49.1 (from pymilvus)\n",
      "  Obtaining dependency information for grpcio<=1.58.0,>=1.49.1 from https://files.pythonhosted.org/packages/a1/9c/ef89aae6948949a891a50e19bb951aac2f7ceb9561fdfdcd07c9b890ed6c/grpcio-1.58.0-cp311-cp311-macosx_10_10_universal2.whl.metadata\n",
      "  Using cached grpcio-1.58.0-cp311-cp311-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in ./lib/python3.11/site-packages (from pymilvus) (4.24.3)\n",
      "Requirement already satisfied: environs<=9.5.0 in ./lib/python3.11/site-packages (from pymilvus) (9.5.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in ./lib/python3.11/site-packages (from pymilvus) (5.8.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in ./lib/python3.11/site-packages (from pymilvus) (2.1.0)\n",
      "Requirement already satisfied: requests in ./lib/python3.11/site-packages (from pymilvus) (2.31.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./lib/python3.11/site-packages (from pymilvus) (13.0.0)\n",
      "Requirement already satisfied: certifi in ./lib/python3.11/site-packages (from minio) (2023.7.22)\n",
      "Requirement already satisfied: urllib3 in ./lib/python3.11/site-packages (from minio) (1.26.18)\n",
      "Collecting argon2-cffi (from minio)\n",
      "  Obtaining dependency information for argon2-cffi from https://files.pythonhosted.org/packages/a4/6a/e8a041599e78b6b3752da48000b14c8d1e8a04ded09c88c714ba047f34f5/argon2_cffi-23.1.0-py3-none-any.whl.metadata\n",
      "  Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pycryptodome (from minio)\n",
      "  Obtaining dependency information for pycryptodome from https://files.pythonhosted.org/packages/ff/96/b0d494defb3346378086848a8ece5ddfd138a66c4a05e038fca873b2518c/pycryptodome-3.20.0-cp35-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading pycryptodome-3.20.0-cp35-abi3-macosx_10_9_universal2.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: typing-extensions in ./lib/python3.11/site-packages (from minio) (4.8.0)\n",
      "Requirement already satisfied: marshmallow>=3.0.0 in ./lib/python3.11/site-packages (from environs<=9.5.0->pymilvus) (3.20.1)\n",
      "Requirement already satisfied: python-dotenv in ./lib/python3.11/site-packages (from environs<=9.5.0->pymilvus) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (1.25.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./lib/python3.11/site-packages (from pandas>=1.2.4->pymilvus) (2023.3)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi->minio)\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./lib/python3.11/site-packages (from requests->pymilvus) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./lib/python3.11/site-packages (from requests->pymilvus) (3.4)\n",
      "Requirement already satisfied: packaging>=17.0 in ./lib/python3.11/site-packages (from marshmallow>=3.0.0->environs<=9.5.0->pymilvus) (23.1)\n",
      "Requirement already satisfied: six>=1.5 in ./lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.16.0)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi->minio)\n",
      "  Obtaining dependency information for cffi>=1.0.1 from https://files.pythonhosted.org/packages/18/6c/0406611f3d5aadf4c5b08f6c095d874aed8dfc2d3a19892707d72536d5dc/cffi-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached cffi-1.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio)\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Downloading pymilvus-2.3.5-py3-none-any.whl (174 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.9/174.9 kB\u001b[0m \u001b[31m260.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached minio-7.2.3-py3-none-any.whl (92 kB)\n",
      "Using cached grpcio-1.58.0-cp311-cp311-macosx_10_10_universal2.whl (9.5 MB)\n",
      "Using cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading pycryptodome-3.20.0-cp35-abi3-macosx_10_9_universal2.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m56.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hUsing cached cffi-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (176 kB)\n",
      "Installing collected packages: pycryptodome, pycparser, grpcio, cffi, argon2-cffi-bindings, argon2-cffi, minio, pymilvus\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.59.3\n",
      "    Uninstalling grpcio-1.59.3:\n",
      "      Successfully uninstalled grpcio-1.59.3\n",
      "  Attempting uninstall: minio\n",
      "    Found existing installation: minio 7.1.16\n",
      "    Uninstalling minio-7.1.16:\n",
      "      Successfully uninstalled minio-7.1.16\n",
      "  Attempting uninstall: pymilvus\n",
      "    Found existing installation: pymilvus 2.3.3\n",
      "    Uninstalling pymilvus-2.3.3:\n",
      "      Successfully uninstalled pymilvus-2.3.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.59.3 requires grpcio>=1.59.3, but you have grpcio 1.58.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 cffi-1.16.0 grpcio-1.58.0 minio-7.2.3 pycparser-2.21 pycryptodome-3.20.0 pymilvus-2.3.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pymilvus minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs for Zilliz Cloud cluster\n",
    "CLUSTER_ENDPOINT=\"\"\n",
    "API_KEY=\"\"\n",
    "TOKEN=\"\"\n",
    "CLUSTER_ID=\"\"\n",
    "CLOUD_REGION=\"\"\n",
    "CLOUD_API_ENDPOINT=\"controller.api.{0}.zillizcloud.com\".format(CLOUD_REGION)\n",
    "COLLECTION_NAME=\"\"\n",
    "\n",
    "# Configs for remote bucket\n",
    "ACCESS_KEY=\"\"\n",
    "SECRET_KEY=\"\"\n",
    "BUCKET_NAME=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 5133k  100 5133k    0     0   436k      0  0:00:11  0:00:11 --:--:--  648k   0      0      0 --:--:--  0:00:01 --:--:--     0\n"
     ]
    }
   ],
   "source": [
    "!curl https://assets.zilliz.com/doc-assets/medium_articles_partial_a13e0f2a.csv \\\n",
    "        --output medium_articles_partial.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import FieldSchema, CollectionSchema, DataType\n",
    "\n",
    "schema = CollectionSchema(\n",
    "    fields=[\n",
    "        FieldSchema(name='id', dtype=DataType.INT64, is_primary=True),\n",
    "        FieldSchema(name='title_vector', dtype=DataType.FLOAT_VECTOR, dim=768),\n",
    "        FieldSchema(name='title', dtype=DataType.VARCHAR, max_length=512),\n",
    "        FieldSchema(name='link', dtype=DataType.VARCHAR, max_length=512),\n",
    "    ],\n",
    "    description=\"A series of articles from medium.com\",\n",
    "    auto_id=False,\n",
    "    enable_dynamic_field=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, Collection\n",
    "\n",
    "# 1. Set up a connection\n",
    "connections.connect(\n",
    "        uri=CLUSTER_ENDPOINT,\n",
    "        token=TOKEN\n",
    ")\n",
    "# 2. Create collection\n",
    "collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
    "\n",
    "# 3. Set index parameters\n",
    "index_params = {\n",
    "    \"index_type\": \"AUTOINDEX\",\n",
    "    \"metric_type\": \"IP\",\n",
    "    \"params\": {}\n",
    "}\n",
    "\n",
    "# 4. Create index\n",
    "collection.create_index(\n",
    "        field_name=\"title_vector\",\n",
    "        index_params=index_params,\n",
    ")\n",
    "\n",
    "# 5. Load the collection\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import RemoteBulkWriter, BulkFileType\n",
    "\n",
    "# Connections parameters to access the remote bucket\n",
    "conn = RemoteBulkWriter.ConnectParam(\n",
    "    endpoint=\"storage.googleapis.com\", # Use \"s3.amazonaws.com\" for AWS S3\n",
    "    access_key=ACCESS_KEY,\n",
    "    secret_key=SECRET_KEY,\n",
    "    bucket_name=BUCKET_NAME, # Use a bucket hosted in the same cloud as the target cluster\n",
    "    secure=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = RemoteBulkWriter(\n",
    "    schema=schema, # Target collection schema\n",
    "    remote_path=\"/\", # Output directory relative to the remote bucket root\n",
    "    segment_size=512*1024*1024, # Maximum segment size when segmenting the raw data\n",
    "    connect_param=conn, # Connection parameters defined above\n",
    "    file_type=BulkFileType.JSON_RB # Type of the generated file.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"medium_articles_partial.csv\") # Use the actual file path to the dataset\n",
    "\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i].to_dict()\n",
    "    row[\"title_vector\"] = [float(x) for x in row[\"title_vector\"][1:-1].split(\",\")]\n",
    "    writer.append_row(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/54859c6c-145d-444d-a596-48a7ee940e00\n"
     ]
    }
   ],
   "source": [
    "print(writer.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 200, 'data': {'jobId': '61c0d0ae-46f8-4eef-a182-8d4e6b52144d'}}\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import bulk_import\n",
    "\n",
    "# Publicly accessible URL for the prepared data in the remote bucket\n",
    "object_url = \"gs://{0}/{1}/\".format(BUCKET_NAME, str(writer.data_path)[1:])\n",
    "# Change `gs` to `s3` for AWS S3\n",
    "\n",
    "# Start bulk-import\n",
    "res = bulk_import(\n",
    "    # Parameters for Zilliz Cloud access\n",
    "    # highlight-next-line\n",
    "    url=CLOUD_API_ENDPOINT,\n",
    "    api_key=API_KEY,\n",
    "    cluster_id=CLUSTER_ID,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    # Parameters for bucket access\n",
    "    object_url=object_url,\n",
    "    access_key=ACCESS_KEY,\n",
    "    secret_key=SECRET_KEY,\n",
    "\n",
    ")\n",
    "\n",
    "print(res.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.5\n",
      "0.5\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pymilvus import get_import_progress\n",
    "\n",
    "job_id = res.json()['data']['jobId']\n",
    "\n",
    "res = get_import_progress(\n",
    "    # highlight-next-line\n",
    "    url=CLOUD_API_ENDPOINT,\n",
    "    api_key=API_KEY,\n",
    "    job_id=job_id,\n",
    "    cluster_id=CLUSTER_ID\n",
    ")\n",
    "\n",
    "print(res.json()[\"data\"][\"readyPercentage\"])\n",
    "\n",
    "# check the bulk-import progress\n",
    "while res.json()[\"data\"][\"readyPercentage\"] < 1:\n",
    "    time.sleep(5)\n",
    "\n",
    "    res = get_import_progress(\n",
    "        # highlight-next-line\n",
    "        url=CLOUD_API_ENDPOINT,\n",
    "        api_key=API_KEY,\n",
    "        job_id=job_id,\n",
    "        cluster_id=CLUSTER_ID\n",
    "    )\n",
    "    \n",
    "    print(res.json()[\"data\"][\"readyPercentage\"])\n",
    "\n",
    "# 0.01   -- import progress 1%\n",
    "# 0.5    -- import progress 50%\n",
    "# 0.5\n",
    "# 1      -- finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 200, 'data': {'tasks': [{'collectionName': 'medium_articles', 'jobId': '61c0d0ae-46f8-4eef-a182-8d4e6b52144d', 'state': 'ImportCompleted'}, {'collectionName': 'medium_articles', 'jobId': 'aec225ca-c8c3-48fe-9605-8507cd0ea3af', 'state': 'ImportFailed'}], 'count': 2, 'currentPage': 1, 'pageSize': 10}}\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import list_import_jobs\n",
    "\n",
    "res = list_import_jobs(\n",
    "    # highlight-next-line\n",
    "    url=CLOUD_API_ENDPOINT,\n",
    "    api_key=API_KEY,\n",
    "    cluster_id=CLUSTER_ID,\n",
    "    page_size=10,\n",
    "    current_page=1,\n",
    ")\n",
    "\n",
    "print(res.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
